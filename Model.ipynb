{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75151110",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "80738d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f6fb8",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fde2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./reviews_Amazon_Instant_Video_5.json\", lines=True, dtype={'overall': np.int64}) # cast \"overall\" (rating) column to float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2a3fb",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts = df['overall'].value_counts()\n",
    "min_val = val_counts.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(1, 6):\n",
    "    vals = df[df['overall'] == i][:min_val]\n",
    "    X += list(vals['reviewText'])\n",
    "    y += list(vals['overall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.67) # train test split with 2/3 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "940edc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nums(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) # remove numbers\n",
    "    text = re.sub(r'_', '', text) # remove underscores\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(preprocessor=remove_nums, stop_words='english')\n",
    "train_x_vectorized = vectorizer.fit_transform(X_train)\n",
    "test_x_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(train_x_vectorized.toarray(), y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "2\n",
      "I thought I was really going to like this movie and was very disappointed.  Right away in the beginning there were so many things that were just unbelievable.  Very shallow, just plain not good.\n"
     ]
    }
   ],
   "source": [
    "i = 14\n",
    "print(nb_classifier.predict(test_x_vectorized[i].toarray()))\n",
    "print(y_test[i])\n",
    "print(X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(max_depth = 5)\n",
    "rf_classifier.fit(train_x_vectorized.toarray(), y_train)\n",
    "[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.308994708994709\n"
     ]
    }
   ],
   "source": [
    "print(nb_classifier.score(test_x_vectorized.toarray(), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f765c978bbf1599ac5ff0eefaab7e6a11f8d68341b098acd75bf14e955615d5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
